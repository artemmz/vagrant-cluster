# Variables for all hosts

iface: eth1

master_ip: "{{ hostvars[groups['master']['ansible_' + iface]['ipv4']['address'] }}"

nfsshare: /home
nfsserver: "{{ master_ip }}"
nfspath: /export

nfsopts: "auto,noatime,nolock,bg,nfsvers=4,intr,tcp,actimeo=1800"

clusteruser: 'hadoop'
clusteruser_home: '/home/hadoop'

hadoop:
    
#Variables for <core-site_xml> - common
    
    fs_default_FS_port: 8020
    nameservice_id: mycluster4

#Variables for <hdfs-site_xml>     
    
    dfs_permissions_superusergroup: hdfs
    dfs_namenode_name_dir: 
       - /namedir1/
       - /namedir2/
    dfs_replication: 3
    dfs_namenode_handler_count: 50
    dfs_blocksize: 67108864
    dfs_datanode_data_dir:
       - /datadir1/
       - /datadir2/
    dfs_datanode_address_port: 50010
    dfs_datanode_http_address_port: 50075
    dfs_datanode_ipc_address_port:  50020
    dfs_namenode_http_address_port: 50070

spark:
    spark_version: "1.0.2-bin-hadoop2"
    spark_download_url: "http://d3kbcqa49mib13.cloudfront.net/spark-1.0.2-bin-hadoop2.tgz"
    spark_root: "/opt/spark/"

mesos:
    mesos_install_prefix: "/usr/local"
