<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Data Analytics on SoftLayer]]></title>
  <link href="http://irifed.github.io/vagrant-cluster/atom.xml" rel="self"/>
  <link href="http://irifed.github.io/vagrant-cluster/"/>
  <updated>2014-12-24T14:09:39+03:00</updated>
  <id>http://irifed.github.io/vagrant-cluster/</id>
  <author>
    <name><![CDATA[Irina Fedulova]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[SoftLayer Cluster Manager]]></title>
    <link href="http://irifed.github.io/vagrant-cluster/blog/2014/12/08/softlayer-cluster-manager/"/>
    <updated>2014-12-08T14:42:10+03:00</updated>
    <id>http://irifed.github.io/vagrant-cluster/blog/2014/12/08/softlayer-cluster-manager</id>
    <content type="html"><![CDATA[<p><em>This article introduces SoftLayer Cluster Manager - a web interface for provisioning a cluster of virtual servers on SoftLayer and automatic deployment of data analytics software on it. For example, users can get an <a href="http://spark.apache.org/">Apache Spark</a> cluster on SoftLayer with just one click.</em></p>

<h2>Introduction</h2>

<p>In the era of Big Data the need for running analytics workloads has become ubiquitous. These workloads are often dynamic: they emerge, grow and scale down depending on the business need and available data. The best place to perform scalable computations is cloud environment with its on-demand delivery. Typical use case on a cloud looks as follows: provision a bunch of instances, install and configure analytics software stack, provide a dataset link or upload it directly to the cluster, analyze data and tear down a whole cluster. Cloud resources are being charged on a pay-per-use basis, so users are interested in minimizing not productive cluster usage time. Cluster deployment should be as easy and fast as possible, so users can focus on performing data analysis and solving their business problems.</p>

<p>At the same time, the landscape of data analytics software has substantially increased during recent years. In addition to traditional MapReduce computational framework we now can use new fast data processing tools like <a href="http://spark.apache.org/">Apache Spark</a>, in-memory file systems like <a href="http://tachyon-project.org">Tachyon</a> and ensure that cluster resources are fully utilized by using management systems like <a href="http://mesos.apache.org/">Apache Mesos</a>. Many of popular data analytics components are being developed by the UC Berkeley&rsquo;s <a href="https://amplab.cs.berkeley.edu">AMPLab</a>. Complete deployment and setup of the full <a href="https://amplab.cs.berkeley.edu/software/">Berkeley Data Analytics Stack</a> (BDAS) is a time consuming and error-prone task when performed manually. Even though there are a lot of powerful cluster management tools available on the market, most of them are commercial, complex to use and at least require some controller server to be provisioned in advance. On the other hand, some of the data analytics software, e.g. Apache Spark, do provide simple command-line scripts for provisioning a cluster on Amazon cloud environment. However, installing installing multiple tools would require managing multiple scripts and performing manual configuration.
In addition,  unfortunately these tools are only available for Amazon cloud, but not for other cloud environments because of the API differences.</p>

<p>In this tutorial we present two tools for automated data analytics cluster provisioning on the SoftLayer cloud environment.</p>

<ul>
<li><a href="http://clustermanager.rekesh.com/">SoftLayer Cluster Manager</a> is a simple web interface for provisioning a data analytics cluster on SoftLayer with few mouse clicks. Its target audience are data science engineers who need a way to quickly bring up a cluster for ad-hoc data analysis. Under the hood SoftLayer Cluster Manager is based on the <code>vagrant-cluster</code> tool mentioned below.</li>
<li><a href="https://github.com/irifed/vagrant-cluster"><code>vagrant-cluster</code></a> is a command-line tool for achieving same goal - provisioning a data analytics cluster on SoftLayer. <code>vagrant-cluster</code> is based on <a href="https://www.vagrantup.com/">Vagrant</a> and <a href="http://www.ansible.com">Ansible</a>. Its target audience are DevOps engineers who can integrate this command-line tool in their usual frameworks.</li>
</ul>


<h2>SoftLayer Cluster Manager</h2>

<p>SoftLayer Cluster Manager provisions virtual instances on SoftLayer on your behalf using your SoftLayer API key and automatically installs and configures software of your choice. As a result, you are getting a Spark or Hadoop or MPI virtual cluster on SoftLayer in approximately 30 minutes with just few clicks.
Since instances are provisioned using your API key, you can see these instances in your SoftLayer portal. You will be charged for instance use as if you have provisioned them yourself.</p>

<p>It is important to note that SoftLayer Cluster Manager is not a fully managed service, like for example Amazon&rsquo;s Elastic MapReduce. SoftLayer Cluster Manager can provision a cluster of virtual servers on SoftLayer and deploy software stack on it, and also destroy the cluster when it is no longer necessary. You can get a fully configured cluster, but at this moment SoftLayer cluster manager does not provide advanced features like automatic reprovisioning of the failed nodes and scaling cluster up and down.</p>

<h3>Creating and setting up your SoftLayer account</h3>

<p>Obviously, to use SoftLayer Cluster Manager you should have a SoftLayer account. If you do not have it already, please refer to this series of <a href="http://thoughtsoncloud.com/2014/06/creating-first-virtual-server-softlayer-billing-options/">blog posts</a> describing the process of creating an account on SoftLayer. In short, as distinguished from other cloud providers, there is no &ldquo;Create an account&rdquo; button on SoftLayer. To create an account, you are required to order at least one virtual server and enter your credit card data first. Your account will be created automatically when your order is placed. You should receive account data via email you&rsquo;ve specified during in the server order page.</p>

<p>To login to the SoftLayer Cluster Manager you should enter SoftLayer username and API key. In order to keep things secure it is recommended to create a separate user within your account for provisioning clusters with SoftLayer Cluster Manager. SoftLayer allows to create multiple users within one master account and fine tune security privileges for each users. <a href="http://thoughtsoncloud.com/2014/07/softlayer-account-now/">This blog post</a> describes creating additional users in the SoftLayer account in detail.</p>

<h3>Using SoftLayer Cluster Manager</h3>

<p>Once you have created a separate user for working with SoftLayer Cluster Manager, create an API key for this user. Steps for getting and API key are described in detailed at <a href="http://knowledgelayer.softlayer.com/procedure/retrieve-your-api-key">SoftLayer knowledge base</a>.</p>

<p>You can now login to the SoftLayer Cluster Manager service using your username and API key at <a href="http://clustermanager.rekesh.com.">http://clustermanager.rekesh.com.</a></p>

<p><img class="center" src="http://irifed.github.io/vagrant-cluster/images/clustermanager/login.png"></p>

<p>After getting through the login page you will be presented a dashboard.
Dashboard displays the list of all clusters that were provisioned by this service using your SoftLayer API key. In the dashboard you can view each cluster&rsquo;s parameters, cluster provisioning logs and destroy each cluster. There is also a Create button which allows to create a new cluster in your account.</p>

<p><img class="center" src="http://irifed.github.io/vagrant-cluster/images/clustermanager/dashboard.png"></p>

<p>To create a cluster you should select number of cluster nodes (virtual servers), datacenter where you want your nodes to be provisioned in, node parameters, e.g. number of CPU cores, RAM and disk size, network speed. There is also an option to specify your SSH key for password-less login to your cluster, if you have one already provisioned in SoftLayer.</p>

<p>SoftLayer Cluster Manager currently can install following software:</p>

<ul>
<li>HDFS from CDH 5</li>
<li>Apache Spark 1.1.0</li>
<li>Mesos</li>
<li>Hive</li>
<li>Cassandra 2.0 (from Datastax repository)</li>
<li>OpenMPI</li>
</ul>


<p><img class="center" src="http://irifed.github.io/vagrant-cluster/images/clustermanager/create.png"></p>

<p>You can also see each cluster&rsquo;s details by clicking &ldquo;View&rdquo; link on the dashboard.
Cluster details page displays all information necessary to login to cluster&rsquo;s master node (master node IP address and password) as well as cluster node parameters.</p>

<p><img class="center" src="http://irifed.github.io/vagrant-cluster/images/clustermanager/details.png"></p>

<p>&ldquo;Logs&rdquo; link displays cluster provisioning logs where you can dynamically watch cluster provisioning and software orchestration process.</p>

<p><img class="center" src="http://irifed.github.io/vagrant-cluster/images/clustermanager/logs.png"></p>

<p>Finally, clicking &ldquo;Delete&rdquo; link will permanently destroy all nodes in your cluster.</p>

<p>All cluster nodes will be password-less accessible from master node and share common file system. Depending on chosen software, this can be either HDFS (for Spark and Hadoop), or NFS (for OpenMPI), or Tachyon. In addition, <code>python-swiftclient</code> package is installed on master node, so you can access data on SoftLayer Object Storage using <code>swift</code> command and your Object Storage credentials, e.g. to download all files with prefix <code>pre</code> from your container:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>swift -A &lt; swift_api_url &gt; -U &lt; swift_user &gt; -K &lt; swift_key &gt; download &lt; your_container &gt; --prefix &lt; pre &gt;</span></code></pre></td></tr></table></div></figure>


<p>You can find <code>swift_api_url</code>, <code>swift_user</code> and <code>swift_key</code> in your container properties in SoftLayer portal.</p>

<h2>Vagrant-Cluster</h2>

<p>SoftLayer Cluster Manager is based on open-source <code>vagrant-cluster</code> tool under the hood. <code>vagrant-cluster</code> is using <a href="https://www.vagrantup.com/">Vagrant</a> with <a href="https://github.com/audiolize/vagrant-softlayer"><code>vagrant-softlayer</code></a> plugin for managing virtual instances on SoftLayer and <a href="http://www.ansible.com">Ansible</a> for installing and configuring data analytics software stack on the cluster.</p>

<p><code>vagrant-cluster</code> is available on Github repository: <a href="https://github.com/irifed/vagrant-cluster.">https://github.com/irifed/vagrant-cluster.</a></p>

<p>To use <code>vagrant-cluster</code> you will have to install Vagrant and Ansible on your computer. However, the benefit of using <code>vagrant-cluster</code> instead of SoftLayer Cluster Manager is that you will not have to expose your SoftLayer API key to any third party.
Detailed installation and usage instructions are provided in the <code>README.md</code> of this repository.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running Examples From Databricks Spark Tutorial]]></title>
    <link href="http://irifed.github.io/vagrant-cluster/blog/2014/10/27/running-spark-training-examples/"/>
    <updated>2014-10-27T12:55:04+03:00</updated>
    <id>http://irifed.github.io/vagrant-cluster/blog/2014/10/27/running-spark-training-examples</id>
    <content type="html"><![CDATA[<p>In this post we show how to run hands-on excercises from <a href="https://databricks-training.s3.amazonaws.com/index.html">Spark Training</a> tutorial prepared by <a href="http://databricks.com/">Databricks</a> on the data analytics cluster provisioned by Vagrant-Cluster tool. Note that cluster provisioning and setup using this tool is described in detail <a href="https://github.com/irifed/vagrant-cluster">here</a>.</p>

<p>Originally Spark Training examples are prepared for running on a local Spark deployment. To run these examples on our cluster on SoftLayer we will have to make some minor modifications, e.g. use different parameters for <code>spark-submit</code>. Here we cover only differences between what was suggested in original Databricks tutorial and what should be done to run examples on the cluster. For detailed description of examples we strongly encourage you to refer to the original <a href="https://databricks-training.s3.amazonaws.com/index.html">Spark Training</a> tutorial.</p>

<h2>Logging in to the cluster</h2>

<p>Assuming that you used <code>vagrant-cluster</code> for cluster provisioning, you are on your local machine in the directory with <code>Vagrantfile</code> of your cluster. Start with logging in to master server:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>user@laptop vagrant-cluster$ ls
</span><span class='line'>LICENSE
</span><span class='line'>README.md
</span><span class='line'>Vagrantfile
</span><span class='line'>ansible-bdas
</span><span class='line'>ansible.cfg
</span><span class='line'>sl_config.yml
</span><span class='line'>sl_config.yml.template
</span><span class='line'>
</span><span class='line'>user@laptop vagrant-cluster$ vagrant ssh master
</span><span class='line'>
</span><span class='line'>Welcome to Ubuntu 14.04.1 LTS (GNU/Linux 3.13.0-36-generic x86_64)
</span><span class='line'>
</span><span class='line'> * Documentation:  https://help.ubuntu.com/
</span><span class='line'>root@master:~#</span></code></pre></td></tr></table></div></figure>


<h2>Running Sample Application</h2>

<p>Download Spark application templates and input data for the Databricks tutorial:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@master:~# wget https://s3-us-west-2.amazonaws.com/databricks-meng/usb.zip
</span><span class='line'>root@master:~# unzip usb.zip</span></code></pre></td></tr></table></div></figure>


<p>Our first task will be to verify that our Spark cluster is working by running a sample application:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@master:~# cd spark-training/simple-app</span></code></pre></td></tr></table></div></figure>


<p>In the Databricks tutorial all examples in <code>spark-training</code> folder are set up to run from local Spark deployment (no cluster) and take input files from local filesystem by default. But here we have a real Spark cluster with HDFS, so we should put our input data to HDFS to be accessible by workers.</p>

<p>For example to run SampleApp we should put some file, e.g. <code>README.md</code> file to HDFS:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@master:~# hadoop fs -put ../spark/README.md /</span></code></pre></td></tr></table></div></figure>


<p>and make corresponding changes to <code>src/main/SimpleApp.scala</code> by adding <code>hdfs:///</code> prefix to input file location, so that <code>SimpleApp.scala</code> file looks like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>...
</span><span class='line'>val logFile = "hdfs:///README.md"
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>Compile and run SimpleApp:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@master:~# sbt assembly
</span><span class='line'>root@master:~# /opt/spark/bin/spark-submit --class "SimpleApp" \ 
</span><span class='line'>    --master spark://master:7077 target/scala-2.10/simple-project_2.10-1.0.jar
</span><span class='line'>...
</span><span class='line'>Lines with a: 83, Lines with b: 38</span></code></pre></td></tr></table></div></figure>


<p>Note that we are running <code>sbt</code> without any prefix paths because SBT is installed system-wide on your cluster. Also we submit SimpleApp to the real Spark cluster instead of local mode using <code>--master spark://master:7077</code> option.</p>

<h2>Data exploration using Spark SQL</h2>

<p>Next, move to the next page of the Databricks tutorial and try running some <a href="https://databricks-training.s3.amazonaws.com/data-exploration-using-spark-sql.html">Spark SQL examples</a>. We will again need to do some tweaks to run examples from Databrick tutorial on our cluster. Namely, Spark SQL section of this tutorial uses input data stored in <code>spark-training/data</code> folder on local disk, but we are going to run on a real cluster, so we should put data to HDFS:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@master:~# cd /root/spark-training
</span><span class='line'>root@master:~# hadoop fs -put data /root/data</span></code></pre></td></tr></table></div></figure>


<p>Now you can run all examples from above mentioned <a href="https://databricks-training.s3.amazonaws.com/data-exploration-using-spark-sql.html">Spark SQL</a> section of Databricks Spark Training tutorial without modifications.</p>

<h2>Stream processing with Spark Streaming</h2>

<p>To run examples from <a href="https://databricks-training.s3.amazonaws.com/realtime-processing-with-spark-streaming.html">Spark Streaming</a> section of the tutorial we again need to do only few modifications. To compile and submit your Spark Streaming application use following commands instead of those suggested in the tutorial:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@master:~# sbt assembly
</span><span class='line'>root@master:~# /opt/spark/bin/spark-submit --master spark://master:7077 \ 
</span><span class='line'>--class "Tutorial" \
</span><span class='line'>--master spark://master:7077 target/scala-2.10/Tutorial-assembly-0.1-SNAPSHOT.jar</span></code></pre></td></tr></table></div></figure>


<p>All other contents of Spark Streaming example can be run without modifications on our cluster.</p>

<h2>Movie Recommendation with MLlib</h2>

<p>This section explains how to use MLlib to make personalized movie recommendations. Please read <a href="https://databricks-training.s3.amazonaws.com/movie-recommendation-with-mllib.html">detailed description</a> of this example in the original Spark Training tutorial.</p>

<p>To run MLlib example on our cluster on SoftLayer we again have to make some modifications.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@master:~# cd /root/spark-training/machine-learning</span></code></pre></td></tr></table></div></figure>


<p>To make personalized movie recommendations, you should first provide your personal ratings for a few movies as described <a href="https://databricks-training.s3.amazonaws.com/movie-recommendation-with-mllib.html#create-training-examples">here</a>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@master:~/spark-training/machine-learning# python bin/rateMovies</span></code></pre></td></tr></table></div></figure>


<p>This script will ask you to provide numerical rating to a set of movies and write result to a file <code>personalRatings.txt</code>.</p>

<p>Move on to the directory where Scala source code for this Movie rating algorithm is stored:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@master:~/spark-training/machine-learning# cd scala</span></code></pre></td></tr></table></div></figure>


<p>Our cluster is running Spark 1.1.0 on top of CDH 5, so original <code>build.sbt</code> file should be modified and look like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import AssemblyKeys._
</span><span class='line'>
</span><span class='line'>assemblySettings
</span><span class='line'>
</span><span class='line'>name := "movielens-als"
</span><span class='line'>
</span><span class='line'>version := "0.1"
</span><span class='line'>
</span><span class='line'>scalaVersion := "2.10.4"
</span><span class='line'>
</span><span class='line'>libraryDependencies += "org.apache.spark" %% "spark-core" % "1.1.0" % "provided"
</span><span class='line'>
</span><span class='line'>libraryDependencies += "org.apache.spark" %% "spark-mllib" % "1.1.0" % "provided"
</span><span class='line'>
</span><span class='line'>libraryDependencies += "org.apache.hadoop" % "hadoop-client" % "2.3.0" % "provided"
</span><span class='line'>
</span><span class='line'>libraryDependencies += "org.apache.hadoop" % "hadoop-hdfs" % "2.3.0" % "provided"</span></code></pre></td></tr></table></div></figure>


<p>You can download this file to your cluster using following command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>wget htts://TODO-TODO/build.sbt</span></code></pre></td></tr></table></div></figure>


<p>After updating <code>build.sbt</code> program can be compiled with SBT assembly command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@master:~/spark-training/machine-learning/scala# sbt assembly</span></code></pre></td></tr></table></div></figure>


<p>To run assembled Spark application use following parameters for <code>spark-submit</code> script:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@master:~/spark-training/machine-learning/scala# /opt/spark/bin/spark-submit \
</span><span class='line'>--master spark://master:7077 \
</span><span class='line'>--class "MovieLensALS" \
</span><span class='line'>target/scala-2.10/movielens-als-assembly-0.1.jar \
</span><span class='line'>hdfs://master:8020/movielens/large ../personalRatings.txt</span></code></pre></td></tr></table></div></figure>


<p>Note that in this command we provide Spark master address <code>spark://master:7077</code>, &ldquo;MovieLensALS&rdquo; class name and assembly jar and two command line parameters for MovieLensALS class: path to <code>movielens/large</code> dataset and path to <code>personalRatings.txt</code> file.</p>

<p>Because you are now running your program on the real Spark cluster, input dataset should be either stored on local file system accessible by all nodes at the same path, or on HDFS. Cluster provisioning script already has preloaded <code>movielens/medium</code> and <code>movielens/large</code> datasets on HDFS of your cluster, so you should provide dataset path as <code>hdfs://master:8020/movielens/medium/</code> or <code>hdfs://master:8020/movielens/large/</code>. Note trailing <code>/</code> at the end of HDFS urls, this is very important for correct constructing of path in <code>MovieLensALS.scala</code>.</p>

<p>Finally, <code>MovieLensALS.scala</code> program is desisgned to read input file from local filesystem, so you should modify a couple of lines in <code>MovieLensALS.scala</code> to read files from HDFS.
Replace line</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>val ratings = sc.textFile(new File(movieLensHomeDir, "ratings.dat").toString).map { line =&gt;</span></code></pre></td></tr></table></div></figure>


<p>
by</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>val ratings = sc.textFile(movieLensHomeDir + "ratings.dat").map { line =&gt;</span></code></pre></td></tr></table></div></figure>


<p>and do the same with <code>val movies = ...</code> line so it looks like</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>val movies = sc.textFile(movieLensHomeDir + "movies.dat").map { line =&gt;</span></code></pre></td></tr></table></div></figure>


<p>Here we simply replaced <code>new File(movieLensHomeDir, "ratings.dat").toString</code> construct by <code>movieLensHomeDir + "ratings.dat"</code>, because <code>new File(...)</code> creates a local File instance from a parent and child path strings, but we do not need this because we provided full HDFS link as a parameter to <code>spark-submit</code>.</p>

<p>Remaining contents of <a href="https://databricks-training.s3.amazonaws.com/movie-recommendation-with-mllib.html">MLlib example</a> does not require any modifications for running on a real cluster.</p>

<h2>Graph Analytics With GraphX</h2>

<p>Start Spark shell as follows:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/opt/spark/bin/spark-shell --master spark://master:7077</span></code></pre></td></tr></table></div></figure>


<p>The only additional step is required for <a href="https://databricks-training.s3.amazonaws.com/graph-analytics-with-graphx.html#load-the-wikipedia-articles">Wikipedia analysis</a> section of this chapter.</p>

<p>Note that Kryo serializer is already enabled by default on your cluster, so you should skip <a href="https://databricks-training.s3.amazonaws.com/graph-analytics-with-graphx.html#constructing-an-end-to-end-graph-analytics-pipeline-on-real-data">steps</a> explaining how to enable it.</p>

<p>Again, original tutorial reads data from local disk, but we should put it to HDFS:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root@master:~# cd /spark-training/
</span><span class='line'>root@master:~# hadoop fs -put data/graphx /data/graphx</span></code></pre></td></tr></table></div></figure>


<p>and do not forget to use correct HDFS path (<code>/data/graphx/...</code> instead of <code>data/graphx/...</code>) when loading Wikipedia articles as RDD:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>val articles: RDD[String] = sc.textFile("/data/graphx/graphx-wiki-vertices.txt")
</span><span class='line'>val links: RDD[String] = sc.textFile("/data/graphx/graphx-wiki-edges.txt")</span></code></pre></td></tr></table></div></figure>


<p>As with previous chapters, all remaining content can be run on the cluster without modifications.</p>
]]></content>
  </entry>
  
</feed>
