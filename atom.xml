<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Data Analytics Clusters on SoftLayer]]></title>
  <link href="http://irifed.github.io/vagrant-cluster/atom.xml" rel="self"/>
  <link href="http://irifed.github.io/vagrant-cluster/"/>
  <updated>2014-10-27T14:52:45+03:00</updated>
  <id>http://irifed.github.io/vagrant-cluster/</id>
  <author>
    <name><![CDATA[Irina Fedulova]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Running Spark Training Examples]]></title>
    <link href="http://irifed.github.io/vagrant-cluster/blog/2014/10/27/running-spark-training-examples/"/>
    <updated>2014-10-27T12:55:04+03:00</updated>
    <id>http://irifed.github.io/vagrant-cluster/blog/2014/10/27/running-spark-training-examples</id>
    <content type="html"><![CDATA[<p>After you have created a data analytics cluster using Vagrant-Cluster tool you certainly will want to see how to use it. Here we present how to run hands-on excercises from <a href="https://databricks-training.s3.amazonaws.com/index.html">Spark Training</a> tutorial prepared by (Databricks)[<a href="http://databricks.com/">http://databricks.com/</a>].</p>

<p>First, get some input data and application templates:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>wget https://s3-us-west-2.amazonaws.com/databricks-meng/usb.zip
</span><span class='line'>unzip usb.zip
</span><span class='line'>cd spark-training/simple-app</span></code></pre></td></tr></table></div></figure>


<h2>Running Sample Application</h2>

<p>In Databrick tutorial examples in <code>spark-training</code> folder are set up to run from local Spark deployment (no cluster) and takes input files from local filesystem by default. But we have a real Spark cluster with HDFS, so we should put our input data to HDFS to be accessible by the cluster, for example to run SampleApp first put some file to HDFS:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hadoop fs -put ../spark/README.md /</span></code></pre></td></tr></table></div></figure>


<p>and make corresponding changes to <code>src/main/SimpleApp.scala</code> by adding <code>hdfs:///</code> prefix to input file location:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>val logFile = "hdfs:///README.md"</span></code></pre></td></tr></table></div></figure>


<p>After this you can just compile and run SimpleApp to verify that Spark cluster is working:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sbt package
</span><span class='line'>$ /opt/spark/bin/spark-submit --class "SimpleApp" \ 
</span><span class='line'>    --master spark://master:7077 target/scala-2.10/simple-project_2.10-1.0.jar
</span><span class='line'>...
</span><span class='line'>Lines with a: 83, Lines with b: 38</span></code></pre></td></tr></table></div></figure>


<p>Note that we are running <code>sbt</code> without any prefix paths because SBT is installed system-wide on your cluster. Also we submit SimpleApp to the real Spark cluster instead of local using <code>--master spark://master:7077</code> option.</p>

<h2>Spark SQL examples</h2>

<p>Next, move to the next page and try running some Spark SQL examples as described (here)[<a href="https://databricks-training.s3.amazonaws.com/data-exploration-using-spark-sql.html">https://databricks-training.s3.amazonaws.com/data-exploration-using-spark-sql.html</a>]. We will again need to do some tweaks to run examples from Databrick tutorial on our cluster. Spark SQL section of tutorial uses input data stored in <code>spark-training/data</code> folder, so we will put it to HDFS</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ cd /root/spark-training
</span><span class='line'>$ hadoop fs -put data /root/data</span></code></pre></td></tr></table></div></figure>


<p>Now you can run all examples from above mentioned (Spark SQL)[<a href="https://databricks-training.s3.amazonaws.com/data-exploration-using-spark-sql.html">https://databricks-training.s3.amazonaws.com/data-exploration-using-spark-sql.html</a>] section of Databricks Spark Training tutorial.</p>

<h2>Spark Streaming</h2>

<p>To run examples from (Spark Streaming)[<a href="https://databricks-training.s3.amazonaws.com/realtime-processing-with-spark-streaming.html">https://databricks-training.s3.amazonaws.com/realtime-processing-with-spark-streaming.html</a>] section of the tutorial we again need to do only few modifications. To compile and submit your Spark Streaming application use following commands instead of those suggested in the tutorial:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sbt assembly
</span><span class='line'>$ /opt/spark/bin/spark-submit --master spark://master:7077 \ 
</span><span class='line'>--class "Tutorial" \
</span><span class='line'>--master spark://master:7077 target/scala-2.10/Tutorial-assembly-0.1-SNAPSHOT.jar</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
</feed>
