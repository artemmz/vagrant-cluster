---
- name: Create AMPCamp data folder
  file: path=/{{ ampcamp['ampcamp_container'] }} state=directory

- name: Download AMPCamp wikistats dataset from SoftLayer Object Store
  # do not change indentation in the long line below
  shell: >
    if [ ! -d /{{ ampcamp['ampcamp_container'] }}/{{ item }} ]; then 
    cd /{{ ampcamp['ampcamp_container'] }};
    swift -A {{ ampcamp['swift_api_url'] }} 
    -U {{ ampcamp['swift_user'] }} -K {{ ampcamp['swift_key'] }} 
    download {{ ampcamp['ampcamp_container'] }} --prefix {{ item }}; 
    fi 
  with_items:
    - wikistats_20090505-01
    - wikistats_20090505_restricted-01
    - movielens
    - wiki_links
    - training.tar.gz

- name: Put AMPCamp data from /ampcamp-data to HDFS
  shell: >
    su - {{ hdfsuser }} -c "hadoop fs -mkdir -p /wiki/pagecounts";
    su - {{ hdfsuser }} -c "hadoop fs -put /{{ ampcamp['ampcamp_container'] }}/wikistats_20090505-01/* /wiki/pagecounts/";
    su - {{ hdfsuser }} -c "hadoop fs -put /{{ ampcamp['ampcamp_container'] }}/wikistats_20090505_restricted-01 /";
    su - {{ hdfsuser }} -c "hadoop fs -put /{{ ampcamp['ampcamp_container'] }}/wiki_links /";
    su - {{ hdfsuser }} -c "hadoop fs -put /{{ ampcamp['ampcamp_container'] }}/movielens /";
  # ignore errors if already exists
  ignore_errors: true

- name: Unpack training stuff to /root
  unarchive: copy=no src="/{{ ampcamp['ampcamp_container'] }}/training.tar.gz" dest=/root/

- name: Update MLlib jar version to run on Spark 0.9.2
  shell: >
    sed -i s/'0.9.0-incubating'/'0.9.2'/ /root/machine-learning/scala/build.sbt

- name: Create some symlinks for convenience
  file: src=/root/training/{{ item }} dest=/root/{{ item }} state=link
  with_items:
    - java-app-template
    - machine-learning
    - scala-app-template
    - streaming

- name: Create /root/spark-ec2 directory to store configs required by AMPCamp examples
  file: path=/root/spark-ec2 state=directory

- name: Create config files required by AMPCamp examples MLlib and GraphX
  template: src={{ item }}.j2 dest=/root/spark-ec2/{{ item }}
  with_items:
    - cluster-url
    - masters



- name: Attempt to start Spark cluster
  shell: "{{ spark['spark_root'] }}/sbin/start-all.sh"
  ignore_errors: true


